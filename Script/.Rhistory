geom_bar(width = 1, stat = "identity", color = "white") +
coord_polar("y", start = 0) +
geom_text(aes(y = df$Value, label = paste(round((Value / sum(df$Value)) * 100), "%")),
color = "white", position = position_stack(vjust = 0.5))+
scale_fill_manual(values = mycols) +
theme_void() +
labs(title = "Proportion of NA's")
# Replace vector1 (< 3 minutes missing) by the most recent non-NA
for (i in 4:10){
for(v in vector1){
HHPC[v,i] <- na.locf(unname(unlist(HHPC[,i])))[v]
}
}
paste("We now have ", sum(is.na(HHPC$Sub_metering_1)), "missing values :",
round(sum(is.na(HHPC$Sub_metering_1)) / nrow(HHPC) * 100, 2),
"% of the data")
for (i in 4:10){
for(v in vector2){
HHPC[v,i] <- (HHPC[v+10080,i] +
HHPC[v+20160,i] +
HHPC[v-10080,i] +
HHPC[v-20160,i])/4
}
}
paste("We now have ", sum(is.na(HHPC$Sub_metering_1)), "missing values :",
round(sum(is.na(HHPC$Sub_metering_1)) / nrow(HHPC) * 100, 2),
"% of the data")
# Replace vector 3 by the mean betweem one week ago and one week ahead
for (i in 4:10){
for(v in vector3){
HHPC[v,i] <- mean(HHPC[v+10080,i], HHPC[v-10080,i])
}
}
paste("We finaly have", sum(is.na(HHPC$Sub_metering_1)), "missing values.")
# Scale conversion in whats
HHPC$kitchen_kwh <- HHPC$Sub_metering_1/1000
HHPC$laundry_kwh <- HHPC$Sub_metering_2/1000
HHPC$waterheat_aircond_kwh <- HHPC$Sub_metering_3/1000
HHPC$Global_active_power_kwh <- HHPC$Global_active_power/60
# Remove columns and add remain
HHPC <- HHPC[,-which(names(HHPC) %in% c("Sub_metering_1","Sub_metering_2","Sub_metering_3"))]  # delete old columns (sub 1, 2, 3)
HHPC$Other_kwh <- HHPC$Global_active_power_kwh - HHPC$kitchen_kwh - HHPC$laundry_kwh - HHPC$waterheat_aircond_kwh
#### DAYLIGHT SAVING #####
Summer_2007 <- which(HHPC$DateTime >= ymd_hms("2007-03-25 01:00:00") & HHPC$DateTime <= ymd_hms("2007-10-28 1:59:00"))
Summer_2008 <- which(HHPC$DateTime >= ymd_hms("2008-03-30 01:00:00") & HHPC$DateTime <= ymd_hms("2008-10-26 1:59:00"))
# New time variables
HHPC$Year <- floor_date(HHPC$DateTime, unit = "year")
HHPC$MonthYear <- floor_date(HHPC$DateTime, unit = "month")
HHPC$WeekYear <- floor_date(HHPC$DateTime, "week")
# Remove 2006 (incomplet year)
HHPC <- HHPC %>% filter(HHPC$year != 2006)
granularity <- list()
group <- as.list(c("Year","MonthYear","WeekYear","Date"))
for(i in group) {
granularity[[i]] <- HHPC %>% group_by_at(i) %>%
summarise(Global_reactive_power = sum(Global_reactive_power),
Global_active_power_kwh = sum(Global_active_power_kwh),
kitchen_kwh = sum(kitchen_kwh),
laundry_kwh = sum(laundry_kwh),
waterheat_aircond_kwh = sum(waterheat_aircond_kwh),
Other_kwh = sum(Other_kwh),
Voltage = mean(Voltage),
Global_intensity = mean(Global_intensity))
}
nrow(granularity$Year) # 4
nrow(granularity$MonthYear) # 47
nrow(granularity$WeekYear) # 204
nrow(granularity$Date)# 1426
granularity$MonthYear$Month <- lubridate::month(granularity$MonthYear$MonthYear, label =  FALSE, abbr = FALSE, locale = "English")
granularity$Date$week <- lubridate::week(granularity$Date$Date)
granularity$MonthYear <- granularity$MonthYear %>% mutate(id = seq.int(nrow(granularity$MonthYear)))
# Load packages
pacman::p_load(forecastHybrid, forecast)
# Which granularity ?
per <- "month"
if (per == "month") {
# Monthly
TS_M <- ts(granularity$MonthYear$Global_active_power_kwh, frequency = 12, start=c(2007, 1))
Training_Set <- window(TS_M, start=c(2007, 1), end=c(2009, 12))
Testing_Set <- window(TS_M, start=c(2010, 1))
h <- length(Testing_Set)
} else if  (per == "week") {
# Weekly
TS_M <- ts(granularity$WeekYear$Global_active_power_kwh, frequency=52, start=c(2007, 1))
Training_Set <- window(TS_M, start=c(2007, 1), end=c(2009, 52))
Testing_Set <- window(TS_M, start=c(2010, 1))
h <- length(Testing_Set)
} else if (per == "day") {
# Daily
TS_M <- ts(granularity$Date$Global_active_power_kwh, frequency=frequency(granularity$Date$Global_active_power_kwh), start=c(2007, 1))
Training_Set <- window(TS_M, start=c(2007, 1), end=c(2009, 364))
Testing_Set <- window(TS_M, start=c(2010, 1))
h <- length(Testing_Set)
}
autoplot(TS_M)
autoplot(Training_Set)
autoplot(Testing_Set)
# TSLM
TSLM <- forecast:::forecast.lm(tslm(Training_Set ~ trend + season), h=h)
TSLM_acc <- forecast::accuracy(TSLM, Testing_Set)
autoplot(TSLM)
forecastfunction <- function(x, h) {
forecast:::forecast.lm(tslm(x ~ trend + season), h=h)
}
e <- tsCV(Training_Set, forecastfunction, h = 1)
TSLM_rmse <- sqrt(mean(e^2, na.rm=TRUE)) # 126
# HoltWinter
HoltWinter <- forecast:::forecast.HoltWinters(HoltWinters(Training_Set, beta=FALSE, gamma=TRUE), h=h)
HoltWinter_acc <- forecast::accuracy(HoltWinter, Testing_Set)
autoplot(HoltWinter)
forecastfunction <- function(x, h) {
forecast:::forecast.HoltWinters(HoltWinters(x, beta=FALSE, gamma=TRUE), h=h)
}
e <- tsCV(Training_Set, forecastfunction, h = 1)
HoltWinter_rmse <- sqrt(mean(e^2, na.rm=TRUE)) # 106
# AUTO-ARIMA
if(per == "month") {
ARIMA <- forecast:::forecast(auto.arima(Training_Set, trace = T), h=h, level=c(80,95))
ARIMA_acc <- forecast::accuracy(ARIMA, Testing_Set)
autoplot(ARIMA)
forecastfunction <- function(x, h) {
forecast:::forecast.Arima(auto.arima(x, stepwise=FALSE, approximation=FALSE), h=h,  level=c(20,50))
}
e <- tsCV(Training_Set, forecastfunction, h = 1)
ARIMA_rmse <- sqrt(mean(e^2, na.rm=TRUE)) # 179
}
# ETS
if(per == "month"){
ETS <- forecast::forecast(ets(Training_Set), h=h)
ETS_acc <- forecast::accuracy(ETS, Testing_Set)
autoplot(ETS)
forecastfunction <- function(x, h) {
forecast::forecast(ets(x), h=h)
}
e <- tsCV(Training_Set, forecastfunction, h = 1)
ETS_rmse <- sqrt(mean(e^2, na.rm=TRUE)) # 183
}
# Hybrid
HModel <- forecast(hybridModel(Training_Set, weights="insample.errors"), h=h)
Hybrid_acc <- forecast::accuracy(HModel, Testing_Set)
autoplot(HModel)
forecastfunction <- function(x, h) {
forecast(hybridModel(x, weights="insample.errors"), h=h)
}
e <- tsCV(Training_Set, forecastfunction, h = 1)
Hybrid_rmse <- sqrt(mean(e^2, na.rm=TRUE)) # 276
# Naive
NaiveModel <- snaive(Training_Set, h=h)
NaiveModel_acc <- forecast::accuracy(NaiveModel, Testing_Set)
autoplot(NaiveModel)
forecastfunction <- function(x, h) {
NaiveModel <- snaive(Training_Set, h=h)
}
e <- tsCV(Training_Set, forecastfunction, h = 1)
NaiveModel_rmse <- sqrt(mean(e^2, na.rm=TRUE)) # 276
# Store metrics
if(per == "month") {
print(results <- data.frame("name" = c("TSLM", "HoltWinter", "ARIMA", "Hybrid", "Hybrid", "Naive"),
"mape" = c(TSLM_acc[2,5], HoltWinter_acc[2,5], ARIMA_acc[2,5], ETS_acc[2,5], Hybrid_acc[2,5], NaiveModel_acc[2,5]),
"rmse_cv" = c(TSLM_rmse, HoltWinter_rmse, ARIMA_rmse, ETS_rmse, Hybrid_rmse, NaiveModel_rmse),
"mase" = c(TSLM_acc[2,6], HoltWinter_acc[2,6], ARIMA_acc[2,6], ETS_acc[2,6], Hybrid_acc[2,6], NaiveModel_acc[2,6]),
"ACF" = c(TSLM_acc[2,7], HoltWinter_acc[2,7], ARIMA_acc[2,7], ETS_acc[2,7], Hybrid_acc[2,7], NaiveModel_acc[2,7])))
} else if (per == "week") {
print(results <- data.frame("name" = c("TSLM", "HoltWinter", "HModel"),
"mape" = c(TSLM_acc[2,5], HoltWinter_acc[2,5], HoltWinter_acc[2,5]),
"rmse_cv" = c(TSLM_rmse, HoltWinter_rmse, HoltWinter_rmse),
"mase" = c(TSLM_acc[2,6], HoltWinter_acc[2,6], HoltWinter_acc[2,6]),
"ACF" = c(TSLM_acc[2,7], HoltWinter_acc[2,7], HoltWinter_acc[2,7])))
}
library(rstudioapi)
library(lubridate)
library(ggpubr)
library(caret)
library(dplyr)
library(corrplot)
setwd(dirname(getActiveDocumentContext()$path))
delivery <- read.csv("deliveries.csv", sep = ";")
clients <- read.csv("clients.csv", sep = ";")
drivers <- read.csv("drivers.csv", sep = ";")
df <- merge(merge(delivery, clients), drivers)
set.seed(20)
TT <- data.frame(cbind(df$pu_lat, df$pu_lon))
pred <- kmeans(TT, 20)
df$arr_1 <- as.factor(pred$cluster)
# Date
df$accepted_at <- ymd_hms(df$accepted_at)
df$arrive_at_pu_at <- ymd_hms(df$arrive_at_pu_at)
df$pu_at <- ymd_hms(df$pu_at)
df$do_at <- ymd_hms(df$do_at)
sum(is.na(df))
df <- df[complete.cases(df), ]
sum(is.na(df))
df_2 <- df %>% mutate(deliverytime = do_at-arrive_at_pu_at)
#summary(aov(deliverytime ~ arr_1, data = df_2))
#summary(aov(deliverytime ~ arr_2, data = df_2))
df_2$deliverytime <- as.numeric(df_2$deliverytime)
df_2$day <- day(df_2$accepted_at)
df_2$month <- month(df_2$accepted_at)
train <- df_2 %>% filter(df_2$accepted_at > "2018-09-01" & df_2$accepted_at < "2018-09-20")
test <- df_2 %>% filter(df_2$accepted_at > "2018-09-20")
names(train)
train2 <- train[,c(1, 7, 8, 9, 10, 11, 16, 17, 20, 21,22, 23,24, 26, 27)]
names(train2)
model <- randomForest::randomForest(deliverytime ~ ., data = train2)
pred <- predict(model, test)
postResample(pred, test$deliverytime)
options(scipen=999)
postResample(pred, test$deliverytime)
ggplot(test, aes(test$accepted_at, test$deliverytime)) +
geom_line()
ggplot(test, aes(test$accepted_at, pred)) +
geom_line()
names(train)
df_2$hour <- hour(df_2$accepted_at)
train <- df_2 %>% filter(df_2$accepted_at > "2018-09-01" & df_2$accepted_at < "2018-09-20")
test <- df_2 %>% filter(df_2$accepted_at > "2018-09-20")
names(train)
train2 <- train[,c(1, 7, 8, 9, 10, 11, 16, 17, 20, 21,22, 23,24, 26, 27, 28)]
model <- randomForest::randomForest(deliverytime ~ ., data = train2)
pred <- predict(model, test)
postResample(pred, test$deliverytime)
summary(df_2$deliverytime)
outliers <- df_2 %>% filter(df_2$deliverytime > 3645)
outliers
cor(outliers$deliverytime, outliers$day)
cor(outliers$deliverytime, outliers$hour)
varImp(model)
varImp(model)
table(outliers$day)
table(outliers$hour)
plot(outliers$hour)
bar(outliers$hour)
plot(as.factor(outliers$hour))
df_2$deliverytime <- df_2$deliverytime / 60
train <- df_2 %>% filter(df_2$accepted_at > "2018-09-01" & df_2$accepted_at < "2018-09-20")
test <- df_2 %>% filter(df_2$accepted_at > "2018-09-20")
train2 <- train[,c(1, 7, 8, 9, 10, 11, 16, 17, 20, 21,22, 23,24, 26, 27, 28)]
model <- randomForest::randomForest(deliverytime ~ ., data = train2)
pred <- predict(model, test)
postResample(pred, test$deliverytime)
varImp(model)
pred
test$deliverytime
postResample(pred, test$deliverytime)
varImp(model)
ggplot(test, aes(test$accepted_at, pred)) +
geom_line()
ggplot(test, aes(test$accepted_at, test$transport_type)) +
geom_point()
test$transport_type
ggplot(test, aes(test$accepted_at, test$transport_type[test$transport_type == "bike"])) +
geom_point()
ggplot(test, aes(test$accepted_at[test$transport_type == "bike"], test$transport_type[test$transport_type == "bike"])) +
geom_point()
setwd(dirname(getActiveDocumentContext()$path))
delivery <- read.csv("deliveries.csv", sep = ";")
clients <- read.csv("clients.csv", sep = ";")
drivers <- read.csv("drivers.csv", sep = ";")
df <- merge(merge(delivery, clients), drivers)
library(esqusse)
library(esquisse)
library(esquisser)
library(esquiser)
library(esquise)
library(esquisse)
install.packages("esquisse")
library(esquisse)
esquisser()
esquisse::esquisser()
names(df)
str(df)
boxplot(df$weight)
summary(aov(weight ~ transport_type, data = df))
ggplot(df, aes(df$transport_type, df$age, color = df$industry)) +
geom_point()
ggplot(df, aes(df$weight, df$age, color = df$transport_type)) +
geom_point()
ggplot(df, aes(df$age, df$weight, color = df$transport_type)) +
geom_point()
ggplot(df, aes(df$age, df$weight, color = df$transport_type)) +
geom_point() +
geom_smooth()
plot(as.factor(df_2$hour))
plot(as.factor(outliers$hour))
plot(as.factor(df_2$hour))
plot(as.factor(outliers$hour))
plot(as.factor(df_2$hour))
plot(as.factor(outliers$hour))
plot(as.factor(df_2$hour))
plot(as.factor(outliers$hour))
plot(as.factor(df_2$hour))
plot(as.factor(outliers$hour))
plot(as.factor(df_2$hour))
plot(as.factor(outliers$hour))
plot(as.factor(df_2$hour))
plot(as.factor(outliers$hour))
plot(as.factor(df_2$hour))
plot(as.factor(outliers$hour))
plot(as.factor(df_2$hour))
plot(as.factor(outliers$hour))
plot(as.factor(df_2$hour))
plot(as.factor(df_2$hour))
plot(as.factor(outliers$hour))
plot(as.factor(df_2$hour))
plot(as.factor(outliers$hour))
plot(as.factor(df_2$hour))
plot(as.factor(outliers$hour))
ggplot(df, aes(df$age, df$weight, color = df$transport_type)) +
geom_point() +
geom_smooth()
delivery <- read.csv("deliveries.csv", sep = ";")
clients <- read.csv("clients.csv", sep = ";")
drivers <- read.csv("drivers.csv", sep = ";")
df <- merge(merge(delivery, clients), drivers)
str(df)
set.seed(20)
TT <- data.frame(cbind(df$pu_lat, df$pu_lon))
pred <- kmeans(TT, 20)
df$arr_1 <- as.factor(pred$cluster)
# Date
df$accepted_at <- ymd_hms(df$accepted_at)
df$arrive_at_pu_at <- ymd_hms(df$arrive_at_pu_at)
df$pu_at <- ymd_hms(df$pu_at)
df$do_at <- ymd_hms(df$do_at)
sum(is.na(df))
df <- df[complete.cases(df), ]
sum(is.na(df))
df_2 <- df %>% mutate(deliverytime = do_at-arrive_at_pu_at)
df_2$deliverytime <- as.numeric(df_2$deliverytime)
df$arr_1 <- as.factor(pred$cluster)
pred <- kmeans(TT, 20)
pred <- kmeans(TT, 20)
df$arr_1 <- as.factor(pred$cluster)
df$arr_1 <- as.factor(pred$cluster)
delivery <- read.csv("deliveries.csv", sep = ";")
clients <- read.csv("clients.csv", sep = ";")
drivers <- read.csv("drivers.csv", sep = ";")
df <- merge(merge(delivery, clients), drivers)
str(df)
set.seed(20)
TT <- data.frame(cbind(df$pu_lat, df$pu_lon))
pred <- kmeans(TT, 20)
df$arr_1 <- as.factor(pred$cluster)
df$arr_1
# Date
df$accepted_at <- ymd_hms(df$accepted_at)
df$arrive_at_pu_at <- ymd_hms(df$arrive_at_pu_at)
df$pu_at <- ymd_hms(df$pu_at)
df$do_at <- ymd_hms(df$do_at)
df <- df[complete.cases(df), ]
df_2 <- df %>% mutate(deliverytime = do_at-arrive_at_pu_at)
names(df_2)
df_2$deliverytime <- as.numeric(df_2$deliverytime)
df_2 %>% group_by(df_2$arr_1) %>% summarise(bla = mean(arr_1))
df_2 %>% group_by(df_2$arr_1) %>% summarise(bla = mean(deliverytime))
#install.packages("kknn")
library(readr)
library(rstudioapi)
library(caret)
#Uploading data set
setwd(dirname(getActiveDocumentContext()$path))
CompleteResponses <- read.csv("../Data/CompleteResponses.csv")
#Exploring data
summary(CompleteResponses)
str(CompleteResponses)
cor(CompleteResponses$salary, CompleteResponses$age)
chisq.test(CompleteResponses$elevel, CompleteResponses$brand)
anova(CompleteResponses$salary, CompleteResponses$brand)
anova(CompleteResponses$salary, CompleteResponses$brand)
summary(aov(salary ~ brand, data = CompleteResponses))
sum(is.na(CompleteResponses))
#Preprocessing
CompleteResponses$elevel<-as.factor(CompleteResponses$elevel)
CompleteResponses$car<-as.factor(CompleteResponses$car)
CompleteResponses$zipcode<-as.factor(CompleteResponses$zipcode)
CompleteResponses$brand<-as.factor(CompleteResponses$brand)
#Plots
plot(CompleteResponses$salary, CompleteResponses$brand)
scatter.smooth(x=CompleteResponses$age, y=CompleteResponses$brand, main="Resp ~ Predictor")
scatter.smooth(x=CompleteResponses$age, y=CompleteResponses$brand, main="Resp ~ Predictor")
boxplot(CompleteResponses$salary)
qqnorm(CompleteResponses$age)
#Training and test sets
inTraining <- createDataPartition(CompleteResponses$brand, p = .75, list = FALSE)
training <- CompleteResponses[inTraining,]
testing <- CompleteResponses[-inTraining,]
nrow(training)
nrow(testing)
#Setseed
set.seed(123)
#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)
#Training model
system.time(KNNFit <- train(brand~., data = training, method = "kknn", trControl=fitControl))
KNNFit
library(readr)
library(rstudioapi)
library(caret)
library(ggplot2)
#Uploading data set
setwd(dirname(getActiveDocumentContext()$path))
CompleteResponses <- read.csv("../Data/CompleteResponses.csv")
setwd(dirname(getActiveDocumentContext()$path))
SurveyIncomplete <- read.csv("../Data/SurveyIncomplete.csv")
#Exploring data
attributes(CompleteResponses)
summary(CompleteResponses)
str(CompleteResponses)
sum(is.na(CompleteResponses))
#Preprocessing
CompleteResponses$elevel<-as.factor(CompleteResponses$elevel)
CompleteResponses$car<-as.factor(CompleteResponses$car)
CompleteResponses$zipcode<-as.factor(CompleteResponses$zipcode)
CompleteResponses$brand<-as.factor(CompleteResponses$brand)
SurveyIncomplete$elevel<-as.factor(SurveyIncomplete$elevel)
SurveyIncomplete$car<-as.factor(SurveyIncomplete$car)
SurveyIncomplete$zipcode<-as.factor(SurveyIncomplete$zipcode)
SurveyIncomplete$brand<-as.factor(SurveyIncomplete$brand)
#Plots
plot(CompleteResponses$elevel, CompleteResponses$brand)
boxplot(CompleteResponses$salary)
boxplot(CompleteResponses$age)
boxplot(CompleteResponses$credit)
boxplot(CompleteResponses$elevel)
boxplot(CompleteResponses$zipcode)
boxplot(CompleteResponses$elevel)
boxplot(CompleteResponses$elevel)
boxplot(CompleteResponses$zipcode)
boxplot(CompleteResponses$car)
qqnorm(CompleteResponses$credit)
#Analysis of correlation for feature selection
summary(aov(CompleteResponses$salary ~ CompleteResponses$brand, data = CompleteResponses))
summary(aov(CompleteResponses$age ~ CompleteResponses$brand, data = CompleteResponses))
summary(aov(CompleteResponses$credit ~ CompleteResponses$brand, data = CompleteResponses))
chisq.test(CompleteResponses$elevel, CompleteResponses$brand)
chisq.test(CompleteResponses$car, CompleteResponses$brand)
chisq.test(CompleteResponses$zipcode, CompleteResponses$brand)
cor(CompleteResponses$salary, CompleteResponses$age)
cor(CompleteResponses$salary, CompleteResponses$credit)
cor(CompleteResponses$age, CompleteResponses$credit)
ggplot(data = CompleteResponses, aes(x=CompleteResponses$salary, y=CompleteResponses$age)) + geom_point()
#Training and testing sets
inTraining <- createDataPartition(CompleteResponses$brand, p = .75, list = FALSE)
training <- CompleteResponses[inTraining,]
testing <- CompleteResponses[-inTraining,]
nrow(training)
nrow(testing)
#SetSeed
set.seed(123)
#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)
#Training model all features OOB Automatic Tuning Grid with a tuneLength of 2
C5.0feat <- train(brand~ ., data = training, method = "C5.0",
trControl=fitControl, tuneLength = 2)
C5.0feat
library(readr)
library(rstudioapi)
library(caret)
#Uploading data set
setwd(dirname(getActiveDocumentContext()$path))
CompleteResponses <- read.csv("../Data/CompleteResponses.csv")
#Exploring data
attributes(CompleteResponses)
summary(CompleteResponses)
str(CompleteResponses)
sum(is.na(CompleteResponses))
#Preprocessing
CompleteResponses$elevel<-as.factor(CompleteResponses$elevel)
CompleteResponses$car<-as.factor(CompleteResponses$car)
CompleteResponses$zipcode<-as.factor(CompleteResponses$zipcode)
CompleteResponses$brand<-as.factor(CompleteResponses$brand)
#Plots
plot(CompleteResponses$elevel, CompleteResponses$brand)
boxplot(CompleteResponses$salary)
boxplot(CompleteResponses$age)
boxplot(CompleteResponses$credit)
boxplot(CompleteResponses$elevel)
boxplot(CompleteResponses$zipcode)
boxplot(CompleteResponses$elevel)
boxplot(CompleteResponses$credit)
qqnorm(CompleteResponses$credit)
#Analysis of variance for feature selection
summary(aov(CompleteResponses$salary ~ CompleteResponses$brand, data = CompleteResponses))
summary(aov(CompleteResponses$age ~ CompleteResponses$brand, data = CompleteResponses))
summary(aov(CompleteResponses$credit ~ CompleteResponses$brand, data = CompleteResponses))
chisq.test(CompleteResponses$elevel, CompleteResponses$brand)
chisq.test(CompleteResponses$car, CompleteResponses$brand)
chisq.test(CompleteResponses$zipcode, CompleteResponses$brand)
cor(CompleteResponses$salary, CompleteResponses$age)
cor(CompleteResponses$salary, CompleteResponses$credit)
cor(CompleteResponses$age, CompleteResponses$credit)
ggplot(data = CompleteResponses,
aes(x=CompleteResponses$salary, y=CompleteResponses$age))  + geom_point()
#Training and test sets
inTraining <- createDataPartition(CompleteResponses$brand, p = .75, list = FALSE)
training <- CompleteResponses[inTraining,]
testing <- CompleteResponses[-inTraining,]
nrow(training)
nrow(testing)
#Setseed
set.seed(123)
#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)
#Dataframe for manual tuning of mtry
rfGrid <- expand.grid(mtry=c(1,2,3,4,5))
#Training model all features OOB
system.time(rffeat <- train(brand~., data = training,
method = "rf", trControl=fitControl, tuneGrid=rfGrid))
rffeat
#Feat selection
varImp(rffeat)
rffeat
